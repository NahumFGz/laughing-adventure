{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.base_models import BaseModels\n",
    "from utils.categorical_encoders import CategoricalEncoders\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Definir seed\n",
    "seed = 16\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2611, 14)\n",
      "TARGET\n",
      "0    1371\n",
      "1    1240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Leer el dataset\n",
    "dataset = pd.read_parquet('./data/2_data_preprocesada.parquet')\n",
    "dataset = dataset.drop(columns=['DF_TYPE'])\n",
    "\n",
    "# Seleccionar aleatoriamente el 10% de los datos\n",
    "dataset = dataset.sample(frac=0.002, random_state=42)\n",
    "print(dataset.shape)\n",
    "print(dataset['TARGET'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Crear dataset con los encoders\n",
    "categorical_encoders = CategoricalEncoders(dataset=dataset)\n",
    "binary_columns, categorical_columns = categorical_encoders.get_binary_categorical_columns()\n",
    "\n",
    "data = categorical_encoders.provider(binary_columns, categorical_columns, method='BackwardDifferenceEncoder')\n",
    "\n",
    "# 3. Split dataset\n",
    "X = data.drop(columns=['TARGET'])\n",
    "y = data['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00: AUC on training data with logistic_regression: 0.816\n",
      "AUC on testing data with logistic_regression: 0.776\n",
      "\n",
      "01: AUC on training data with gradient_boosting: 0.893\n",
      "AUC on testing data with gradient_boosting: 0.818\n",
      "\n",
      "02: AUC on training data with catboost: 0.942\n",
      "AUC on testing data with catboost: 0.823\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 982, number of negative: 1106\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 2088, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.470307 -> initscore=-0.118914\n",
      "[LightGBM] [Info] Start training from score -0.118914\n",
      "03: AUC on training data with lgbm: 0.971\n",
      "AUC on testing data with lgbm: 0.808\n",
      "\n",
      "04: AUC on training data with xgboost: 0.985\n",
      "AUC on testing data with xgboost: 0.798\n",
      "\n",
      "05: AUC on training data with mlp: 0.855\n",
      "AUC on testing data with mlp: 0.792\n",
      "\n",
      "06: AUC on training data with decision_tree: 0.998\n",
      "AUC on testing data with decision_tree: 0.660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Entrenar modelos\n",
    "base_models = BaseModels()\n",
    "name_models = ['logistic_regression', 'gradient_boosting', 'catboost', 'lgbm', 'xgboost', 'mlp', 'decision_tree']\n",
    "\n",
    "all_models = []\n",
    "all_results = []\n",
    "all_predict_test = []\n",
    "for i, model_name in enumerate(name_models):\n",
    "    model = base_models.provider(model_name)\n",
    "    model.fit(X_train, y_train)\n",
    "    all_models.append(model)\n",
    "    \n",
    "    predict_train = model.predict_proba(X_train)[:, 1]\n",
    "    predict_test = model.predict_proba(X_test)[:, 1]\n",
    "    all_predict_test.append(predict_test)\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, predict_train)\n",
    "    test_auc = roc_auc_score(y_test, predict_test)\n",
    "\n",
    "    # Calcular accuracy, sensitivity, specificity\n",
    "    test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, test_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    gini = 2 * test_auc - 1\n",
    "\n",
    "    all_results.append((model_name, train_auc, test_auc, accuracy, sensitivity, specificity, gini))\n",
    "\n",
    "    print(f\"{str(i).zfill(2)}: AUC on training data with {model_name}: {train_auc:.3f}\")\n",
    "    print(f\"AUC on testing data with {model_name}: {test_auc:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.745 (+/- 0.038)\n"
     ]
    }
   ],
   "source": [
    "# Validación cruzada (Cross-Validation)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Grid Search: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score from Grid Search: 0.768\n"
     ]
    }
   ],
   "source": [
    "# Búsqueda en malla (Grid Search)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=seed), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "print(f\"Best parameters from Grid Search: {grid_search.best_params_}\")\n",
    "print(f\"Best score from Grid Search: {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Random Search: {'max_depth': 10, 'min_samples_leaf': 9, 'min_samples_split': 4, 'n_estimators': 125}\n",
      "Best score from Random Search: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Búsqueda aleatoria (Random Search)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11)\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=seed), param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1, random_state=seed)\n",
    "random_search.fit(X, y)\n",
    "print(f\"Best parameters from Random Search: {random_search.best_params_}\")\n",
    "print(f\"Best score from Random Search: {random_search.best_score_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
